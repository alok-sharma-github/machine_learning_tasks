{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\alok\\\\Desktop\\\\Inzint\\\\datasets\\\\demonetization-tweets_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(path, encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'favorited', 'favoriteCount', 'replyToSN', 'created',\n",
      "       'truncated', 'replyToSID', 'statusSource', 'screenName', 'retweetCount',\n",
      "       'isRetweet', 'retweeted'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>favorited</th>\n",
       "      <th>favoriteCount</th>\n",
       "      <th>replyToSN</th>\n",
       "      <th>created</th>\n",
       "      <th>truncated</th>\n",
       "      <th>replyToSID</th>\n",
       "      <th>statusSource</th>\n",
       "      <th>screenName</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>isRetweet</th>\n",
       "      <th>retweeted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @rssurjewala: Critical question: Was PayTM ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/23/2016 18:40</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>HASHTAGFARZIWAL</td>\n",
       "      <td>331</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @roshankar: Former FinSec, RBI Dy Governor,...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/23/2016 18:40</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>rahulja13034944</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @satishacharya: Reddy Wedding! @mail_today ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/23/2016 18:39</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://cpimharyana.com\" rel=\"nofollow...</td>\n",
       "      <td>CPIMBadli</td>\n",
       "      <td>120</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @gauravcsawant: Rs 40 lakh looted from a ba...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/23/2016 18:38</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>bhodia1</td>\n",
       "      <td>637</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @sumitbhati2002: Many opposition leaders ar...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/23/2016 18:38</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>sumitbhati2002</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  favorited  \\\n",
       "0  RT @rssurjewala: Critical question: Was PayTM ...      False   \n",
       "1  RT @roshankar: Former FinSec, RBI Dy Governor,...      False   \n",
       "2  RT @satishacharya: Reddy Wedding! @mail_today ...      False   \n",
       "3  RT @gauravcsawant: Rs 40 lakh looted from a ba...      False   \n",
       "4  RT @sumitbhati2002: Many opposition leaders ar...      False   \n",
       "\n",
       "   favoriteCount replyToSN           created  truncated  replyToSID  \\\n",
       "0              0       NaN  11/23/2016 18:40      False         NaN   \n",
       "1              0       NaN  11/23/2016 18:40      False         NaN   \n",
       "2              0       NaN  11/23/2016 18:39      False         NaN   \n",
       "3              0       NaN  11/23/2016 18:38      False         NaN   \n",
       "4              0       NaN  11/23/2016 18:38      False         NaN   \n",
       "\n",
       "                                        statusSource       screenName  \\\n",
       "0  <a href=\"http://twitter.com/download/android\" ...  HASHTAGFARZIWAL   \n",
       "1  <a href=\"http://twitter.com/download/android\" ...  rahulja13034944   \n",
       "2  <a href=\"http://cpimharyana.com\" rel=\"nofollow...        CPIMBadli   \n",
       "3  <a href=\"http://twitter.com/download/android\" ...          bhodia1   \n",
       "4  <a href=\"http://twitter.com/download/android\" ...   sumitbhati2002   \n",
       "\n",
       "   retweetCount  isRetweet  retweeted  \n",
       "0           331       True      False  \n",
       "1            12       True      False  \n",
       "2           120       True      False  \n",
       "3           637       True      False  \n",
       "4             1       True      False  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @RNTata2000: The government\\x92s bold implementation of the demonetization programme needs the nation\\x92s support. https://t.co/tx1ZILSor8'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[df[\"retweetCount\"].idxmax()][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+', '', text) # urls\n",
    "    text = re.sub(r'@\\w+', '', text) # mentions\n",
    "    text = re.sub(r'rt', '', text) # retweet indi\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # special char\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "        \n",
    "    cleaned_text = ' '.join(tokens) # join token back\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    critical question paytm informed demonetizatio...\n",
       "1    former finsec rbi dy governor cbdt chair harva...\n",
       "2      reddy wedding caoon demonetization reddywedding\n",
       "3    rs 40 lakh looted bank kishtwar jampk third in...\n",
       "4    many opposition leaders demonetization respect...\n",
       "Name: cleaned_text, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def generate_sentiment(text):\n",
    "    # Create a TextBlob object\n",
    "    blob = TextBlob(text)\n",
    "    \n",
    "    # Get polarity and subjectivity\n",
    "    sentiment_polarity = blob.sentiment.polarity\n",
    "    sentiment_subjectivity = blob.sentiment.subjectivity\n",
    "    \n",
    "    # Define sentiment labels based on polarity and subjectivity\n",
    "    if sentiment_polarity > 0:\n",
    "        if sentiment_subjectivity > 0:\n",
    "            sentiment_label = 'Positive & Subjective'\n",
    "        else:\n",
    "            sentiment_label = 'Positive & Objective'\n",
    "    elif sentiment_polarity < 0:\n",
    "        if sentiment_subjectivity > 0:\n",
    "            sentiment_label = 'Negative & Subjective'\n",
    "        else:\n",
    "            sentiment_label = 'Negative & Objective'\n",
    "    else:\n",
    "        if sentiment_subjectivity > 0:\n",
    "            sentiment_label = 'Neutral & Subjective'\n",
    "        else:\n",
    "            sentiment_label = 'Neutral & Objective'\n",
    "    \n",
    "    return sentiment_polarity, sentiment_subjectivity, sentiment_label\n",
    "\n",
    "# Apply sentiment analysis function to the 'cleaned_text' column and unpack the results into three new columns\n",
    "df['polarity'], df['subjectivity'], df['sentiment'] = zip(*df['cleaned_text'].apply(generate_sentiment))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Neutral & Objective      3351\n",
       "Positive & Subjective    2727\n",
       "Negative & Subjective    1101\n",
       "Neutral & Subjective      271\n",
       "Negative & Objective       13\n",
       "Positive & Objective        7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>favorited</th>\n",
       "      <th>favoriteCount</th>\n",
       "      <th>replyToSN</th>\n",
       "      <th>created</th>\n",
       "      <th>truncated</th>\n",
       "      <th>replyToSID</th>\n",
       "      <th>statusSource</th>\n",
       "      <th>screenName</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>isRetweet</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @rssurjewala: Critical question: Was PayTM ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/23/2016 18:40</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>HASHTAGFARZIWAL</td>\n",
       "      <td>331</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>critical question paytm informed demonetizatio...</td>\n",
       "      <td>Positive &amp; Subjective</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.577778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @roshankar: Former FinSec, RBI Dy Governor,...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/23/2016 18:40</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>rahulja13034944</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>former finsec rbi dy governor cbdt chair harva...</td>\n",
       "      <td>Neutral &amp; Objective</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @satishacharya: Reddy Wedding! @mail_today ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/23/2016 18:39</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://cpimharyana.com\" rel=\"nofollow...</td>\n",
       "      <td>CPIMBadli</td>\n",
       "      <td>120</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>reddy wedding caoon demonetization reddywedding</td>\n",
       "      <td>Neutral &amp; Objective</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @gauravcsawant: Rs 40 lakh looted from a ba...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/23/2016 18:38</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>bhodia1</td>\n",
       "      <td>637</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>rs 40 lakh looted bank kishtwar jampk third in...</td>\n",
       "      <td>Neutral &amp; Objective</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @sumitbhati2002: Many opposition leaders ar...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/23/2016 18:38</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>sumitbhati2002</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>many opposition leaders demonetization respect...</td>\n",
       "      <td>Positive &amp; Subjective</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7465</th>\n",
       "      <td>RT @rahulroushan: Prohibition is Demonetizatio...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/11/2017 15:57</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>AniruddhasT</td>\n",
       "      <td>337</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>prohibition demonetization 20 kept quiet poor ...</td>\n",
       "      <td>Positive &amp; Subjective</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.511111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7466</th>\n",
       "      <td>Can cash -- or the end of cash -- end poverty ...</td>\n",
       "      <td>False</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/11/2017 14:52</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"https://about.twitter.com/products/tw...</td>\n",
       "      <td>JustinSandefur</td>\n",
       "      <td>27</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>cash end cash end povey india feat</td>\n",
       "      <td>Neutral &amp; Objective</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7467</th>\n",
       "      <td>RT @Vidyut: How India became Bill Gates' guine...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/11/2017 14:36</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>SukhvinderShahi</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>india became bill gates guinea pig conspiracy ...</td>\n",
       "      <td>Positive &amp; Subjective</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7468</th>\n",
       "      <td>N d modi fans-d true nationalists of the count...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/11/2017 14:19</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>JusteyAlex</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>n modi fansd true nationalists country stil th...</td>\n",
       "      <td>Negative &amp; Subjective</td>\n",
       "      <td>-0.105556</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7469</th>\n",
       "      <td>RT @Stupidosaur: @Vidyut B team of BJP. CIA ba...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/11/2017 14:13</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>Stupidosaur</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>b team bjp cia baby cctv evm vvpat suppo surgi...</td>\n",
       "      <td>Neutral &amp; Objective</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7470 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  favorited  \\\n",
       "0     RT @rssurjewala: Critical question: Was PayTM ...      False   \n",
       "1     RT @roshankar: Former FinSec, RBI Dy Governor,...      False   \n",
       "2     RT @satishacharya: Reddy Wedding! @mail_today ...      False   \n",
       "3     RT @gauravcsawant: Rs 40 lakh looted from a ba...      False   \n",
       "4     RT @sumitbhati2002: Many opposition leaders ar...      False   \n",
       "...                                                 ...        ...   \n",
       "7465  RT @rahulroushan: Prohibition is Demonetizatio...      False   \n",
       "7466  Can cash -- or the end of cash -- end poverty ...      False   \n",
       "7467  RT @Vidyut: How India became Bill Gates' guine...      False   \n",
       "7468  N d modi fans-d true nationalists of the count...      False   \n",
       "7469  RT @Stupidosaur: @Vidyut B team of BJP. CIA ba...      False   \n",
       "\n",
       "      favoriteCount replyToSN           created  truncated  replyToSID  \\\n",
       "0                 0       NaN  11/23/2016 18:40      False         NaN   \n",
       "1                 0       NaN  11/23/2016 18:40      False         NaN   \n",
       "2                 0       NaN  11/23/2016 18:39      False         NaN   \n",
       "3                 0       NaN  11/23/2016 18:38      False         NaN   \n",
       "4                 0       NaN  11/23/2016 18:38      False         NaN   \n",
       "...             ...       ...               ...        ...         ...   \n",
       "7465              0       NaN   4/11/2017 15:57      False         NaN   \n",
       "7466             36       NaN   4/11/2017 14:52      False         NaN   \n",
       "7467              0       NaN   4/11/2017 14:36      False         NaN   \n",
       "7468              0       NaN   4/11/2017 14:19       True         NaN   \n",
       "7469              0       NaN   4/11/2017 14:13      False         NaN   \n",
       "\n",
       "                                           statusSource       screenName  \\\n",
       "0     <a href=\"http://twitter.com/download/android\" ...  HASHTAGFARZIWAL   \n",
       "1     <a href=\"http://twitter.com/download/android\" ...  rahulja13034944   \n",
       "2     <a href=\"http://cpimharyana.com\" rel=\"nofollow...        CPIMBadli   \n",
       "3     <a href=\"http://twitter.com/download/android\" ...          bhodia1   \n",
       "4     <a href=\"http://twitter.com/download/android\" ...   sumitbhati2002   \n",
       "...                                                 ...              ...   \n",
       "7465  <a href=\"http://twitter.com/download/android\" ...      AniruddhasT   \n",
       "7466  <a href=\"https://about.twitter.com/products/tw...   JustinSandefur   \n",
       "7467  <a href=\"http://twitter.com/download/android\" ...  SukhvinderShahi   \n",
       "7468  <a href=\"http://twitter.com/download/android\" ...       JusteyAlex   \n",
       "7469  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...      Stupidosaur   \n",
       "\n",
       "      retweetCount  isRetweet  retweeted  \\\n",
       "0              331       True      False   \n",
       "1               12       True      False   \n",
       "2              120       True      False   \n",
       "3              637       True      False   \n",
       "4                1       True      False   \n",
       "...            ...        ...        ...   \n",
       "7465           337       True      False   \n",
       "7466            27      False      False   \n",
       "7467            12       True      False   \n",
       "7468             0      False      False   \n",
       "7469             2       True      False   \n",
       "\n",
       "                                           cleaned_text  \\\n",
       "0     critical question paytm informed demonetizatio...   \n",
       "1     former finsec rbi dy governor cbdt chair harva...   \n",
       "2       reddy wedding caoon demonetization reddywedding   \n",
       "3     rs 40 lakh looted bank kishtwar jampk third in...   \n",
       "4     many opposition leaders demonetization respect...   \n",
       "...                                                 ...   \n",
       "7465  prohibition demonetization 20 kept quiet poor ...   \n",
       "7466                 cash end cash end povey india feat   \n",
       "7467  india became bill gates guinea pig conspiracy ...   \n",
       "7468  n modi fansd true nationalists country stil th...   \n",
       "7469  b team bjp cia baby cctv evm vvpat suppo surgi...   \n",
       "\n",
       "                  sentiment  polarity  subjectivity  \n",
       "0     Positive & Subjective  0.150000      0.577778  \n",
       "1       Neutral & Objective  0.000000      0.000000  \n",
       "2       Neutral & Objective  0.000000      0.000000  \n",
       "3       Neutral & Objective  0.000000      0.000000  \n",
       "4     Positive & Subjective  0.500000      0.500000  \n",
       "...                     ...       ...           ...  \n",
       "7465  Positive & Subjective  0.033333      0.511111  \n",
       "7466    Neutral & Objective  0.000000      0.000000  \n",
       "7467  Positive & Subjective  0.166667      0.333333  \n",
       "7468  Negative & Subjective -0.105556      0.694444  \n",
       "7469    Neutral & Objective  0.000000      0.000000  \n",
       "\n",
       "[7470 rows x 16 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favoriteCount</th>\n",
       "      <th>replyToSID</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7470.000000</td>\n",
       "      <td>4.170000e+02</td>\n",
       "      <td>7470.000000</td>\n",
       "      <td>7470.000000</td>\n",
       "      <td>7470.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.397992</td>\n",
       "      <td>8.381674e+17</td>\n",
       "      <td>222.755020</td>\n",
       "      <td>0.059531</td>\n",
       "      <td>0.267831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>39.558552</td>\n",
       "      <td>2.543166e+16</td>\n",
       "      <td>412.126728</td>\n",
       "      <td>0.225993</td>\n",
       "      <td>0.298545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.458400e+17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.013830e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.528180e+17</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.539960e+17</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3166.000000</td>\n",
       "      <td>8.554540e+17</td>\n",
       "      <td>5170.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       favoriteCount    replyToSID  retweetCount     polarity  subjectivity\n",
       "count    7470.000000  4.170000e+02   7470.000000  7470.000000   7470.000000\n",
       "mean        1.397992  8.381674e+17    222.755020     0.059531      0.267831\n",
       "std        39.558552  2.543166e+16    412.126728     0.225993      0.298545\n",
       "min         0.000000  6.458400e+17      0.000000    -1.000000      0.000000\n",
       "25%         0.000000  8.013830e+17      1.000000     0.000000      0.000000\n",
       "50%         0.000000  8.528180e+17     38.000000     0.000000      0.200000\n",
       "75%         0.000000  8.539960e+17    197.000000     0.187500      0.450000\n",
       "max      3166.000000  8.554540e+17   5170.000000     1.000000      1.000000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1       former finsec rbi dy governor cbdt chair harva...\n",
      "2         reddy wedding caoon demonetization reddywedding\n",
      "3       rs 40 lakh looted bank kishtwar jampk third in...\n",
      "8       former finsec rbi dy governor cbdt chair harva...\n",
      "10                    vote demonetization modi survey app\n",
      "                              ...                        \n",
      "7452    thursday jpal cofounder abhijit banerjee talki...\n",
      "7454    issue shoage charge withdrawal atm paid charge...\n",
      "7457    mind_itarnab goswami slams pathological liar s...\n",
      "7466                   cash end cash end povey india feat\n",
      "7469    b team bjp cia baby cctv evm vvpat suppo surgi...\n",
      "Name: cleaned_text, Length: 3371, dtype: object\n",
      "\n",
      " 30      demonetization gives hilarious shagun suggesti...\n",
      "37      survey result far demonetization 5 lakh respon...\n",
      "42      demonetization gives hilarious shagun suggesti...\n",
      "54      demonetization gives hilarious shagun suggesti...\n",
      "63      survey result far demonetization 5 lakh respon...\n",
      "                              ...                        \n",
      "7326    pathetic service cc executives said delay cos ...\n",
      "7329    yes people like u banned like demonetization u...\n",
      "7345              funny demonetize includes word demonize\n",
      "7374    twitter needs edu00a0u00bdedu00b8u00a1next u27...\n",
      "7400    stream discussing possible solutions demonetiz...\n",
      "Name: cleaned_text, Length: 256, dtype: object\n"
     ]
    }
   ],
   "source": [
    "text_with_subjectivity_zero = df.loc[df['subjectivity'] == 0, 'cleaned_text']\n",
    "print(\"\\n\",text_with_subjectivity_zero)\n",
    "\n",
    "text_with_subjectivity_one = df.loc[df['subjectivity'] == 1, 'cleaned_text']\n",
    "print(\"\\n\",text_with_subjectivity_one)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30      demonetization gives hilarious shagun suggesti...\n",
      "37      survey result far demonetization 5 lakh respon...\n",
      "42      demonetization gives hilarious shagun suggesti...\n",
      "54      demonetization gives hilarious shagun suggesti...\n",
      "63      survey result far demonetization 5 lakh respon...\n",
      "                              ...                        \n",
      "7326    pathetic service cc executives said delay cos ...\n",
      "7329    yes people like u banned like demonetization u...\n",
      "7345              funny demonetize includes word demonize\n",
      "7374    twitter needs edu00a0u00bdedu00b8u00a1next u27...\n",
      "7400    stream discussing possible solutions demonetiz...\n",
      "Name: cleaned_text, Length: 256, dtype: object\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 293     one greatest computer scientists dr vijay bhat...\n",
      "389     sir saw ur speech demonetization rs awesome u ...\n",
      "853     demonetization like pushup bra looks impressiv...\n",
      "905     perfect demonetization message mind blowing en...\n",
      "1061    institutionalized lets hope best things come d...\n",
      "1067    institutionalized lets hope best things come d...\n",
      "2265    read aicle benefit demonetization best thing c...\n",
      "2736    one greatest computer scientists dr vijay bhat...\n",
      "2748    one greatest computer scientists dr vijay bhat...\n",
      "2791    demonetization best period two company patym p...\n",
      "3874    best could done need upgrade best goi demoneti...\n",
      "4627    superb sonu nigam goes keshless renders suppo ...\n",
      "7057    megaupload 2 bitcache kim dotcom goes yt demon...\n",
      "Name: cleaned_text, dtype: object\n",
      "\n",
      " 480     pathetic journalism media thought get stds atm...\n",
      "987     isnt awful demonetization woes hear field pane...\n",
      "3118    demonetization beginning says pm modi bjp mps ...\n",
      "3123    demonetization beginning says pm modi bjp mps ...\n",
      "3201    demonetization beginning says pm modi bjp mps ...\n",
      "3235    basically evil moodi made people comfoable sta...\n",
      "3725    says india worst demonetization things sta imp...\n",
      "3772    says india worst demonetization things sta imp...\n",
      "3790    says india worst demonetization things sta imp...\n",
      "3820    says india worst demonetization things sta imp...\n",
      "3832    bbcjustinr says india worst demonetization thi...\n",
      "4605    pathetic condition sbi morena tiraha ambah bra...\n",
      "6287                     demonetization terrible idea btw\n",
      "6428    g initiative worst implementation like demonet...\n",
      "7326    pathetic service cc executives said delay cos ...\n",
      "Name: cleaned_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "text_with_polarity_one = df.loc[df['polarity'] == 1, 'cleaned_text']\n",
    "print(\"\\n\",text_with_polarity_one)\n",
    "\n",
    "text_with_polarity_minus_one = df.loc[df['polarity'] == -1, 'cleaned_text']\n",
    "print(\"\\n\",text_with_polarity_minus_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "bow_matrix = count_vectorizer.fit_transform(df['cleaned_text'])\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['cleaned_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encode_polarity(score):\n",
    "    if score > 0:\n",
    "        return 'Positive'\n",
    "    elif score < 0:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "df['polarity_encoded'] = df['polarity'].apply(encode_polarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_text'], df['polarity_encoded'], test_size=0.2, random_state=42)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9203480589022758\n",
      "Random Forest Accuracy: 0.9263721552878179\n"
     ]
    }
   ],
   "source": [
    "logistic_reg = LogisticRegression(max_iter=1000)\n",
    "logistic_reg.fit(X_train_tfidf, y_train)\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "random_forest.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_lr = logistic_reg.predict(X_test_tfidf)\n",
    "y_pred_rf = random_forest.predict(X_test_tfidf)\n",
    "\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_lr)\n",
    "print(\"Random Forest Accuracy:\", accuracy_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch and Randomized Search- Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'criterion': 'entropy', 'n_estimators': 200}\n",
      "Best Score: 0.8895463510848126\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Assuming you have already imported necessary libraries\n",
    "\n",
    "# Read the data\n",
    "phish = pd.read_csv(\"C:\\\\Users\\\\alok\\\\Desktop\\\\Inzint\\\\datasets\\\\PhishingData (1).csv\")\n",
    "\n",
    "# Define the parameters for grid search\n",
    "params = {\"criterion\": [\"gini\", \"entropy\"], \"n_estimators\": [100, 150, 200, 250]}  # Corrected 'n_estimator' to 'n_estimators'\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = phish.drop([\"id\", \"Result\"], axis=1)\n",
    "y = phish.Result\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(), param_grid=params, cv=3, scoring=\"accuracy\")\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Extract the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alok\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 150, 'criterion': 'entropy'}\n",
      "Best Score: 0.8934911242603549\n"
     ]
    }
   ],
   "source": [
    "# Initialize RandomizedSearchCV\n",
    "randomized_search = RandomizedSearchCV(estimator=RandomForestClassifier(), param_distributions=params, n_iter=10, cv=3, scoring=\"accuracy\", random_state=42)\n",
    "\n",
    "# Fit the randomized search to the data\n",
    "randomized_search.fit(X_train, y_train)\n",
    "\n",
    "# Extract the best parameters and best score\n",
    "best_params = randomized_search.best_params_\n",
    "best_score = randomized_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8997050147492626\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have already imported necessary libraries\n",
    "\n",
    "# Read the data\n",
    "phish = pd.read_csv(\"C:\\\\Users\\\\alok\\\\Desktop\\\\Inzint\\\\datasets\\\\PhishingData (1).csv\")\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = phish.drop([\"id\", \"Result\"], axis=1)\n",
    "y = phish.Result\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Initialize and fit the RandomForestClassifier\n",
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate accuracy using accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8377581120943953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alok\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming you have already imported necessary libraries\n",
    "\n",
    "# Read the data\n",
    "phish = pd.read_csv(\"C:\\\\Users\\\\alok\\\\Desktop\\\\Inzint\\\\datasets\\\\PhishingData (1).csv\")\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = phish.drop([\"id\", \"Result\"], axis=1)\n",
    "y = phish.Result\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Initialize Adaboost classifier\n",
    "adaboost_clf = AdaBoostClassifier()\n",
    "\n",
    "# Train the classifier\n",
    "adaboost_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = adaboost_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8997050147492626\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming you have already imported necessary libraries\n",
    "\n",
    "# Read the data\n",
    "phish = pd.read_csv(\"C:\\\\Users\\\\alok\\\\Desktop\\\\Inzint\\\\datasets\\\\PhishingData (1).csv\")\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = phish.drop([\"id\", \"Result\"], axis=1)\n",
    "y = phish.Result\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the decision tree classifier to the training data\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9026548672566371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alok\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming you have already imported necessary libraries\n",
    "\n",
    "# Read the data\n",
    "phish = pd.read_csv(\"C:\\\\Users\\\\alok\\\\Desktop\\\\Inzint\\\\datasets\\\\PhishingData (1).csv\")\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = phish.drop([\"id\", \"Result\"], axis=1)\n",
    "y = phish.Result\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Initialize Adaboost classifier\n",
    "adaboost_clf = AdaBoostClassifier(estimator=DecisionTreeClassifier())\n",
    "\n",
    "# Train the classifier\n",
    "adaboost_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = adaboost_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\alok\\\\Desktop\\\\Inzint\\\\datasets\\\\NBA.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name', 'GP', 'MIN', 'PTS', 'FGM', 'FGA', 'FG%', '3P Made', '3PA',\n",
      "       '3P%', 'FTM', 'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK',\n",
      "       'TOV', 'TARGET_5Yrs'],\n",
      "      dtype='object')\n",
      "Name           0\n",
      "GP             0\n",
      "MIN            0\n",
      "PTS            0\n",
      "FGM            0\n",
      "FGA            0\n",
      "FG%            0\n",
      "3P Made        0\n",
      "3PA            0\n",
      "3P%            0\n",
      "FTM            0\n",
      "FTA            0\n",
      "FT%            0\n",
      "OREB           0\n",
      "DREB           0\n",
      "REB            0\n",
      "AST            0\n",
      "STL            0\n",
      "BLK            0\n",
      "TOV            0\n",
      "TARGET_5Yrs    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "df.dropna(inplace=True)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>...</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brandon Ingram</td>\n",
       "      <td>36</td>\n",
       "      <td>27.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>34.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>69.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andrew Harrison</td>\n",
       "      <td>35</td>\n",
       "      <td>26.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>23.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JaKarr Sampson</td>\n",
       "      <td>74</td>\n",
       "      <td>15.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>42.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malik Sealy</td>\n",
       "      <td>58</td>\n",
       "      <td>11.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>42.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>68.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matt Geiger</td>\n",
       "      <td>48</td>\n",
       "      <td>11.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9</td>\n",
       "      <td>67.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>Chris Smith</td>\n",
       "      <td>80</td>\n",
       "      <td>15.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>14.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>79.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>Brent Price</td>\n",
       "      <td>68</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>35.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>16.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>Marlon Maxey</td>\n",
       "      <td>43</td>\n",
       "      <td>12.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>64.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>Litterial Green</td>\n",
       "      <td>52</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>43.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>Jon Barry</td>\n",
       "      <td>47</td>\n",
       "      <td>11.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>36.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>33.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1329 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name  GP   MIN  PTS  FGM  FGA   FG%  3P Made  3PA   3P%  ...  \\\n",
       "0      Brandon Ingram  36  27.4  7.4  2.6  7.6  34.7      0.5  2.1  25.0  ...   \n",
       "1     Andrew Harrison  35  26.9  7.2  2.0  6.7  29.6      0.7  2.8  23.5  ...   \n",
       "2      JaKarr Sampson  74  15.3  5.2  2.0  4.7  42.2      0.4  1.7  24.4  ...   \n",
       "3         Malik Sealy  58  11.6  5.7  2.3  5.5  42.6      0.1  0.5  22.6  ...   \n",
       "4         Matt Geiger  48  11.5  4.5  1.6  3.0  52.4      0.0  0.1   0.0  ...   \n",
       "...               ...  ..   ...  ...  ...  ...   ...      ...  ...   ...  ...   \n",
       "1335      Chris Smith  80  15.8  4.3  1.6  3.6  43.3      0.0  0.2  14.3  ...   \n",
       "1336      Brent Price  68  12.6  3.9  1.5  4.1  35.8      0.1  0.7  16.7  ...   \n",
       "1337     Marlon Maxey  43  12.1  5.4  2.2  3.9  55.0      0.0  0.0   0.0  ...   \n",
       "1338  Litterial Green  52  12.0  4.5  1.7  3.8  43.9      0.0  0.2  10.0  ...   \n",
       "1339        Jon Barry  47  11.7  4.4  1.6  4.4  36.9      0.4  1.3  33.3  ...   \n",
       "\n",
       "      FTA   FT%  OREB  DREB  REB  AST  STL  BLK  TOV  TARGET_5Yrs  \n",
       "0     2.3  69.9   0.7   3.4  4.1  1.9  0.4  0.4  1.3          0.0  \n",
       "1     3.4  76.5   0.5   2.0  2.4  3.7  1.1  0.5  1.6          0.0  \n",
       "2     1.3  67.0   0.5   1.7  2.2  1.0  0.5  0.3  1.0          0.0  \n",
       "3     1.3  68.9   1.0   0.9  1.9  0.8  0.6  0.1  1.0          1.0  \n",
       "4     1.9  67.4   1.0   1.5  2.5  0.3  0.3  0.4  0.8          1.0  \n",
       "...   ...   ...   ...   ...  ...  ...  ...  ...  ...          ...  \n",
       "1335  1.5  79.2   0.4   0.8  1.2  2.5  0.6  0.2  0.8          0.0  \n",
       "1336  1.0  79.4   0.4   1.1  1.5  2.3  0.8  0.0  1.3          1.0  \n",
       "1337  1.6  64.3   1.5   2.3  3.8  0.3  0.3  0.4  0.9          0.0  \n",
       "1338  1.8  62.5   0.2   0.4  0.7  2.2  0.4  0.1  0.8          1.0  \n",
       "1339  1.0  67.3   0.2   0.7  0.9  1.4  0.7  0.1  0.9          1.0  \n",
       "\n",
       "[1329 rows x 21 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression without XGBoost: 0.7147147147147147\n",
      "Accuracy of XGBoost Classifier: 0.7357357357357357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alok\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "X = df.drop([\"TARGET_5Yrs\", \"Name\"], axis=1)\n",
    "y = df[\"TARGET_5Yrs\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Initialize and train logistic regression without XGBoost\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# Predictions without XGBoost\n",
    "y_pred_lr = logistic_regression.predict(X_test)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Accuracy of Logistic Regression without XGBoost:\", accuracy_lr)\n",
    "\n",
    "# Initialize and train logistic regression with XGBoost\n",
    "xgboost_model = xgb.XGBClassifier(learning_rate = 0.3, n_estimators = 25)\n",
    "xgboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions with XGBoost\n",
    "y_pred_xgb = xgboost_model.predict(X_test)\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "print(\"Accuracy of XGBoost Classifier:\", accuracy_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
